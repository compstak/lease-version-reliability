{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jisooryu/Projects/lease-version-reliability\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training (train.py) -> Get classifier and processed df, df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import pickle \n",
    "import structlog\n",
    "\n",
    "from train.common.logging import initialize_logging\n",
    "from train.common.file_io import upload_models, upload_dataset\n",
    "from train.config.settings import settings\n",
    "from train.data.database_io import (\n",
    "    get_all_data,\n",
    "    get_labels,\n",
    "    get_reliable_data,\n",
    ")\n",
    "\n",
    "from train.features.features import feature_engineering\n",
    "from train.model.model import (\n",
    "    get_column_names,\n",
    "    get_split_columns,\n",
    "    train_multioutput_classifiers,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Connector for Python Version: 2.7.0, Python Version: 3.9.10, Platform: macOS-12.6.1-arm64-arm-64bit\n",
      "This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "Setting use_openssl_only mode to False\n",
      "query: [SELECT cv.id, cv.submitter_person_id, lds.logo, cv.comp_data_id AS comp_data_id_...]\n",
      "query execution done\n",
      "Snowflake Connector for Python Version: 2.7.0, Python Version: 3.9.10, Platform: macOS-12.6.1-arm64-arm-64bit\n",
      "This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n",
      "query: [SELECT cv.id, cv.submitter_person_id, lds.logo, cv.comp_data_id AS comp_data_id_...]\n",
      "query execution done\n",
      "closed\n",
      "No async queries seem to be running, deleting session\n",
      "1314249\n",
      "2755895\n",
      "\u001b[2m2022-12-14 14:29:27.564175\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mCreating Data Labels          \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \n",
      "Calculating Labels: tenant_name\n",
      "closed\n",
      "No async queries seem to be running, deleting session\n",
      "Calculating Labels: space_type_id\n",
      "Calculating Labels: transaction_size\n",
      "Calculating Labels: starting_rent\n",
      "Calculating Labels: execution_date\n",
      "Calculating Labels: commencement_date\n",
      "Calculating Labels: lease_term\n",
      "Calculating Labels: expiration_date\n",
      "Calculating Labels: work_value\n",
      "Calculating Labels: free_months\n",
      "Calculating Labels: transaction_type_id\n",
      "Calculating Labels: rent_bumps_percent_bumps\n",
      "Calculating Labels: rent_bumps_dollar_bumps\n",
      "Calculating Labels: lease_type_id\n",
      "Calculating Labels: tenant_name\n",
      "Calculating Labels: space_type_id\n",
      "Calculating Labels: transaction_size\n",
      "Calculating Labels: starting_rent\n",
      "Calculating Labels: execution_date\n",
      "Calculating Labels: commencement_date\n",
      "Calculating Labels: lease_term\n",
      "Calculating Labels: expiration_date\n",
      "Calculating Labels: work_value\n",
      "Calculating Labels: free_months\n",
      "Calculating Labels: transaction_type_id\n",
      "Calculating Labels: rent_bumps_percent_bumps\n",
      "Calculating Labels: rent_bumps_dollar_bumps\n",
      "Calculating Labels: lease_type_id\n",
      "\u001b[2m2022-12-14 14:51:45.100837\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFeature Engineering - Reliable Data\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \n",
      "\u001b[2m2022-12-14 14:52:17.211381\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mFeature Engineering - All Data\u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \n",
      "\u001b[2m2022-12-14 14:53:27.288013\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel Training                \u001b[0m [\u001b[34m\u001b[1m__main__\u001b[0m] \n",
      "tenant_name_label - Accuracy : 0.8680437376523287\n",
      "tenant_name_label - F1 : 0.929300254879603\n",
      "1    1108907\n",
      "0     169165\n",
      "Name: tenant_name_label, dtype: int64\n",
      "----------------------------------\n",
      "space_type_id_label - Accuracy : 0.9693020904480454\n",
      "space_type_id_label - F1 : 0.9844001945876217\n",
      "1    900373\n",
      "0     29328\n",
      "Name: space_type_id_label, dtype: int64\n",
      "----------------------------------\n",
      "transaction_size_label - Accuracy : 0.9507544386865747\n",
      "transaction_size_label - F1 : 0.9747424588429712\n",
      "1    1205352\n",
      "0      62478\n",
      "Name: transaction_size_label, dtype: int64\n",
      "----------------------------------\n",
      "starting_rent_label - Accuracy : 0.7784658140413362\n",
      "starting_rent_label - F1 : 0.8683177182876465\n",
      "1    848851\n",
      "0    263006\n",
      "Name: starting_rent_label, dtype: int64\n",
      "----------------------------------\n",
      "execution_date_label - Accuracy : 0.910216198050857\n",
      "execution_date_label - F1 : 0.9529106487148101\n",
      "1    731342\n",
      "0     72087\n",
      "Name: execution_date_label, dtype: int64\n",
      "----------------------------------\n",
      "commencement_date_label - Accuracy : 0.8946461036925585\n",
      "commencement_date_label - F1 : 0.9443321849741619\n",
      "1    570673\n",
      "0     67367\n",
      "Name: commencement_date_label, dtype: int64\n",
      "----------------------------------\n",
      "lease_term_label - Accuracy : 0.9066103832118312\n",
      "lease_term_label - F1 : 0.9510096175959734\n",
      "1    1086044\n",
      "0     111464\n",
      "Name: lease_term_label, dtype: int64\n",
      "----------------------------------\n",
      "expiration_date_label - Accuracy : 0.9045930105170903\n",
      "expiration_date_label - F1 : 0.9498744523026671\n",
      "1    330256\n",
      "0     34860\n",
      "Name: expiration_date_label, dtype: int64\n",
      "----------------------------------\n",
      "work_value_label - Accuracy : 0.8577631943162946\n",
      "work_value_label - F1 : 0.9233565868589096\n",
      "1    743628\n",
      "0    123409\n",
      "Name: work_value_label, dtype: int64\n",
      "----------------------------------\n",
      "free_months_label - Accuracy : 0.8892719389247998\n",
      "free_months_label - F1 : 0.9413792617837174\n",
      "1    836175\n",
      "0    103647\n",
      "Name: free_months_label, dtype: int64\n",
      "----------------------------------\n",
      "transaction_type_id_label - Accuracy : 0.9178218775315972\n",
      "transaction_type_id_label - F1 : 0.9571272351115708\n",
      "1    810252\n",
      "0     72339\n",
      "Name: transaction_type_id_label, dtype: int64\n",
      "----------------------------------\n",
      "rent_bumps_percent_bumps_label - Accuracy : 0.9364614101147662\n",
      "rent_bumps_percent_bumps_label - F1 : 0.967033224145999\n",
      "1    413668\n",
      "0     29840\n",
      "Name: rent_bumps_percent_bumps_label, dtype: int64\n",
      "----------------------------------\n",
      "rent_bumps_dollar_bumps_label - Accuracy : 0.9331639450934217\n",
      "rent_bumps_dollar_bumps_label - F1 : 0.9650070569912882\n",
      "1    149733\n",
      "0     11631\n",
      "Name: rent_bumps_dollar_bumps_label, dtype: int64\n",
      "----------------------------------\n",
      "lease_type_id_label - Accuracy : 0.8699454738467477\n",
      "lease_type_id_label - F1 : 0.9294824834515057\n",
      "1    716162\n",
      "0    112795\n",
      "Name: lease_type_id_label, dtype: int64\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "initialize_logging(settings.ENV)\n",
    "logger = structlog.get_logger(\n",
    "    \n",
    ")\n",
    "# training data (masters with >3 versions within it)\n",
    "reliable_data = get_reliable_data()\n",
    "\n",
    "# all version data needed to export a reliability score\n",
    "all_data = get_all_data()\n",
    "\n",
    "# # submitter name for display purposes when exporting validation data\n",
    "# submitter_name = get_submitter_info()\n",
    "\n",
    "print(len(reliable_data))\n",
    "print(len(all_data))\n",
    "\n",
    "attributes = settings.ATTRIBUTES\n",
    "\n",
    "col_names_correct, col_names_filled, col_names_label = get_column_names(\n",
    "    attributes,\n",
    ")\n",
    "\n",
    "logger.info(\"Creating Data Labels\")\n",
    "data = get_labels(reliable_data, attributes)\n",
    "all_data = get_labels(all_data, attributes)\n",
    "\n",
    "logger.info(\"Feature Engineering - Reliable Data\")\n",
    "df = feature_engineering(\n",
    "    data,\n",
    "    col_names_label,\n",
    "    col_names_filled,\n",
    "    col_names_correct,\n",
    "    attributes,\n",
    ")\n",
    "\n",
    "logger.info(\"Feature Engineering - All Data\")\n",
    "df_all = feature_engineering(\n",
    "    all_data, \n",
    "    col_names_label,\n",
    "    col_names_filled,\n",
    "    col_names_correct,\n",
    "    attributes,\n",
    ")\n",
    "\n",
    "logger.info(\"Model Training\")\n",
    "x_cols, y_cols = get_split_columns(df.columns)\n",
    "model_dict = train_multioutput_classifiers(df, x_cols, y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_all' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import typing\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import structlog\n",
    "\n",
    "from train.config.settings import settings\n",
    "\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "\n",
    "def get_web_identity_token() -> str:\n",
    "    \"\"\"\n",
    "    Get token value from filepath\n",
    "    \"\"\"\n",
    "    token = \"\"\n",
    "    with open(settings.AWS_WEB_IDENTITY_TOKEN_FILE) as f:  # type: ignore\n",
    "        token = f.read().strip()\n",
    "\n",
    "    return token\n",
    "\n",
    "\n",
    "def get_aws_cred() -> typing.Any:\n",
    "    \"\"\"\n",
    "    Get AWS credential\n",
    "    \"\"\"\n",
    "    token = get_web_identity_token()\n",
    "    sts_client = boto3.client(\"sts\")\n",
    "    assumed_role_object = sts_client.assume_role_with_web_identity(\n",
    "        RoleArn=settings.AWS_ROLE_ARN,\n",
    "        RoleSessionName=\"SalesLinkageSession\",\n",
    "        WebIdentityToken=token,\n",
    "    )\n",
    "\n",
    "    return assumed_role_object[\"Credentials\"]\n",
    "\n",
    "\n",
    "def get_s3_resource() -> typing.Any:\n",
    "    \"\"\"\n",
    "    Get S3 resource\n",
    "    \"\"\"\n",
    "    if not settings.AWS_WEB_IDENTITY_TOKEN_FILE:\n",
    "        s3_resource = boto3.resource(\"s3\")\n",
    "    else:\n",
    "        cred = get_aws_cred()\n",
    "        s3_resource = boto3.resource(\n",
    "            \"s3\",\n",
    "            aws_access_key_id=cred[\"AccessKeyId\"],\n",
    "            aws_secret_access_key=cred[\"SecretAccessKey\"],\n",
    "            aws_session_token=cred[\"SessionToken\"],\n",
    "        )\n",
    "\n",
    "    return s3_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch.config.settings import settings \n",
    "\n",
    "def upload_models() -> None:\n",
    "    \"\"\"\n",
    "    Upload the model to S3 bucket\n",
    "    \"\"\"\n",
    "\n",
    "    s3 = get_s3_resource()\n",
    "    object_name = f\"{settings.PROJECT_NAME}/models/{settings.ENV}.model.tar.gz\"\n",
    "    file_name = f\"{settings.MODEL_DIR}model.tar.gz\"\n",
    "\n",
    "    try:\n",
    "        shutil.make_archive(\n",
    "            settings.MODEL_DIR + \"model\",\n",
    "            \"gztar\",\n",
    "            settings.MODEL_DIR,\n",
    "        )\n",
    "\n",
    "        s3.Bucket(settings.MODELS_S3_BUCKET).upload_file(\n",
    "            file_name,\n",
    "            object_name.format(settings.ENV),\n",
    "        )\n",
    "\n",
    "        os.remove(file_name)\n",
    "        logger.debug(\"Successfully uploaded models\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "            logger.error(\"Permission denied when trying to upload file.\")\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msettings\u001b[39m.\u001b[39mMODEL_DIR\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00msettings\u001b[39m.\u001b[39mMODEL_NAME\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m handle:\n\u001b[1;32m      2\u001b[0m     pickle\u001b[39m.\u001b[39mdump(model_dict, handle, protocol\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL)\n\u001b[0;32m----> 4\u001b[0m upload_models()\n",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m, in \u001b[0;36mupload_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msettings\u001b[39m.\u001b[39mMODEL_DIR\u001b[39m}\u001b[39;00m\u001b[39mmodel.tar.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     shutil\u001b[39m.\u001b[39;49mmake_archive(\n\u001b[1;32m     14\u001b[0m         settings\u001b[39m.\u001b[39;49mMODEL_DIR \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mgztar\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m         settings\u001b[39m.\u001b[39;49mMODEL_DIR,\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     s3\u001b[39m.\u001b[39mBucket(settings\u001b[39m.\u001b[39mMODELS_S3_BUCKET)\u001b[39m.\u001b[39mupload_file(\n\u001b[1;32m     20\u001b[0m         file_name,\n\u001b[1;32m     21\u001b[0m         object_name\u001b[39m.\u001b[39mformat(settings\u001b[39m.\u001b[39mENV),\n\u001b[1;32m     22\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     os\u001b[39m.\u001b[39mremove(file_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/shutil.py:1083\u001b[0m, in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m group\n\u001b[1;32m   1082\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     filename \u001b[39m=\u001b[39m func(base_name, base_dir, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1084\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[39mif\u001b[39;00m root_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/shutil.py:936\u001b[0m, in \u001b[0;36m_make_tarball\u001b[0;34m(base_name, base_dir, compress, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m    934\u001b[0m tar \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39mopen(archive_name, \u001b[39m'\u001b[39m\u001b[39mw|\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m tar_compression)\n\u001b[1;32m    935\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     tar\u001b[39m.\u001b[39;49madd(base_dir, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m_set_uid_gid)\n\u001b[1;32m    937\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    938\u001b[0m     tar\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:1985\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[39mif\u001b[39;00m recursive:\n\u001b[1;32m   1984\u001b[0m         \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(name)):\n\u001b[0;32m-> 1985\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(name, f), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(arcname, f),\n\u001b[1;32m   1986\u001b[0m                     recursive, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1989\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:1979\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[39mif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misreg():\n\u001b[1;32m   1978\u001b[0m     \u001b[39mwith\u001b[39;00m bltn_open(name, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m-> 1979\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maddfile(tarinfo, f)\n\u001b[1;32m   1981\u001b[0m \u001b[39melif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misdir():\n\u001b[1;32m   1982\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:2007\u001b[0m, in \u001b[0;36mTarFile.addfile\u001b[0;34m(self, tarinfo, fileobj)\u001b[0m\n\u001b[1;32m   2005\u001b[0m \u001b[39m# If there's data to follow, append it.\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2007\u001b[0m     copyfileobj(fileobj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfileobj, tarinfo\u001b[39m.\u001b[39;49msize, bufsize\u001b[39m=\u001b[39;49mbufsize)\n\u001b[1;32m   2008\u001b[0m     blocks, remainder \u001b[39m=\u001b[39m \u001b[39mdivmod\u001b[39m(tarinfo\u001b[39m.\u001b[39msize, BLOCKSIZE)\n\u001b[1;32m   2009\u001b[0m     \u001b[39mif\u001b[39;00m remainder \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:250\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buf) \u001b[39m<\u001b[39m bufsize:\n\u001b[1;32m    249\u001b[0m         \u001b[39mraise\u001b[39;00m exception(\u001b[39m\"\u001b[39m\u001b[39munexpected end of data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m     dst\u001b[39m.\u001b[39;49mwrite(buf)\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m remainder \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    253\u001b[0m     buf \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mread(remainder)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:435\u001b[0m, in \u001b[0;36m_Stream.write\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(s)\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomptype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtar\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 435\u001b[0m     s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcmp\u001b[39m.\u001b[39;49mcompress(s)\n\u001b[1;32m    436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__write(s)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(f\"{settings.MODEL_DIR}/{settings.MODEL_NAME}\", \"wb\") as handle:\n",
    "    pickle.dump(model_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "upload_models()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_pickle(f\"{settings.DATA_DIR}/processed/reliable_data\")\n",
    "df_all = pd.read_pickle(f\"{settings.DATA_DIR}/processed/all_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lease-version-reliability-3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60cc9bfb98a58446eb0c16bbb13e9240f211415c72e6a30127570db27246e8c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
