{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jisooryu/Projects/lease-version-reliability\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload processed data (df, df_all) to S3 (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias df_all\n"
     ]
    }
   ],
   "source": [
    "#read df, df_all \n",
    "\n",
    "%store -r df \n",
    "%store -r df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import typing\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "import structlog\n",
    "\n",
    "from train.config.settings import settings\n",
    "\n",
    "logger = structlog.get_logger()\n",
    "\n",
    "\n",
    "def get_web_identity_token() -> str:\n",
    "    \"\"\"\n",
    "    Get token value from filepath\n",
    "    \"\"\"\n",
    "    token = \"\"\n",
    "    with open(settings.AWS_WEB_IDENTITY_TOKEN_FILE) as f:  # type: ignore\n",
    "        token = f.read().strip()\n",
    "\n",
    "    return token\n",
    "\n",
    "\n",
    "def get_aws_cred() -> typing.Any:\n",
    "    \"\"\"\n",
    "    Get AWS credential\n",
    "    \"\"\"\n",
    "    token = get_web_identity_token()\n",
    "    sts_client = boto3.client(\"sts\")\n",
    "    assumed_role_object = sts_client.assume_role_with_web_identity(\n",
    "        RoleArn=settings.AWS_ROLE_ARN,\n",
    "        RoleSessionName=\"SalesLinkageSession\",\n",
    "        WebIdentityToken=token,\n",
    "    )\n",
    "\n",
    "    return assumed_role_object[\"Credentials\"]\n",
    "\n",
    "\n",
    "def get_s3_resource() -> typing.Any:\n",
    "    \"\"\"\n",
    "    Get S3 resource\n",
    "    \"\"\"\n",
    "    if not settings.AWS_WEB_IDENTITY_TOKEN_FILE:\n",
    "        s3_resource = boto3.resource(\"s3\")\n",
    "    else:\n",
    "        cred = get_aws_cred()\n",
    "        s3_resource = boto3.resource(\n",
    "            \"s3\",\n",
    "            aws_access_key_id=cred[\"AccessKeyId\"],\n",
    "            aws_secret_access_key=cred[\"SecretAccessKey\"],\n",
    "            aws_session_token=cred[\"SessionToken\"],\n",
    "        )\n",
    "\n",
    "    return s3_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataset(directory:str) -> None: \n",
    "    \"\"\"\n",
    "    Upload processed dataset to S3 bucket \n",
    "    \"\"\"\n",
    "    #\"processed\" folder is created --> removes files but not the folder \n",
    "    \n",
    "    s3 = get_s3_resource()\n",
    "    object_name = f\"{settings.PROJECT_NAME}/{settings.DATA_DIR}/{directory}/{settings.ENV}.dataset.tar.gz\"\n",
    "    file_name = f\"{settings.DATA_DIR}/{directory}/dataset.tar.gz\"\n",
    "\n",
    "    try:\n",
    "        shutil.make_archive(\n",
    "            f\"{settings.DATA_DIR}/{directory}\" + \"/dataset\",\n",
    "            \"gztar\",\n",
    "            settings.DATA_DIR,\n",
    "        )\n",
    "\n",
    "        s3.Bucket(settings.MODELS_S3_BUCKET).upload_file(\n",
    "            file_name,\n",
    "            object_name.format(settings.ENV),\n",
    "        )\n",
    "\n",
    "        os.remove(file_name)\n",
    "        # os.rmdir(directory)\n",
    "        logger.debug(\"Successfully uploaded dataset\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "            logger.error(\"Permission denied when trying to upload file.\")\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(df, handle, protocol\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39mHIGHEST_PROTOCOL)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msettings\u001b[39m.\u001b[39mDATA_DIR\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/processed\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/all_data\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m handle:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(df_all, handle, protocol\u001b[39m=\u001b[39;49mpickle\u001b[39m.\u001b[39;49mHIGHEST_PROTOCOL)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open(f\"{settings.DATA_DIR}\"+\"/processed\"+\"/reliable_data\", \"wb\") as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f\"{settings.DATA_DIR}\"+\"/processed\"+\"/all_data\", \"wb\") as handle:\n",
    "    pickle.dump(df_all, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m upload_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mprocessed\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb Cell 8\u001b[0m in \u001b[0;36mupload_dataset\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msettings\u001b[39m.\u001b[39mDATA_DIR\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m/dataset.tar.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     shutil\u001b[39m.\u001b[39;49mmake_archive(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00msettings\u001b[39m.\u001b[39;49mDATA_DIR\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdirectory\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/dataset\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mgztar\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         settings\u001b[39m.\u001b[39;49mDATA_DIR,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     s3\u001b[39m.\u001b[39mBucket(settings\u001b[39m.\u001b[39mMODELS_S3_BUCKET)\u001b[39m.\u001b[39mupload_file(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         file_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         object_name\u001b[39m.\u001b[39mformat(settings\u001b[39m.\u001b[39mENV),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jisooryu/Projects/lease-version-reliability/notebooks/upload_data.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     os\u001b[39m.\u001b[39mremove(file_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/shutil.py:1083\u001b[0m, in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1080\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m group\n\u001b[1;32m   1082\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     filename \u001b[39m=\u001b[39m func(base_name, base_dir, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1084\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[39mif\u001b[39;00m root_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/shutil.py:936\u001b[0m, in \u001b[0;36m_make_tarball\u001b[0;34m(base_name, base_dir, compress, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m    934\u001b[0m tar \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39mopen(archive_name, \u001b[39m'\u001b[39m\u001b[39mw|\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m tar_compression)\n\u001b[1;32m    935\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     tar\u001b[39m.\u001b[39;49madd(base_dir, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m_set_uid_gid)\n\u001b[1;32m    937\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    938\u001b[0m     tar\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:1985\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[39mif\u001b[39;00m recursive:\n\u001b[1;32m   1984\u001b[0m         \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(name)):\n\u001b[0;32m-> 1985\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(name, f), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(arcname, f),\n\u001b[1;32m   1986\u001b[0m                     recursive, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1989\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:1985\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     \u001b[39mif\u001b[39;00m recursive:\n\u001b[1;32m   1984\u001b[0m         \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39mlistdir(name)):\n\u001b[0;32m-> 1985\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(name, f), os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(arcname, f),\n\u001b[1;32m   1986\u001b[0m                     recursive, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[1;32m   1988\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1989\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:1979\u001b[0m, in \u001b[0;36mTarFile.add\u001b[0;34m(self, name, arcname, recursive, filter)\u001b[0m\n\u001b[1;32m   1977\u001b[0m \u001b[39mif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misreg():\n\u001b[1;32m   1978\u001b[0m     \u001b[39mwith\u001b[39;00m bltn_open(name, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m-> 1979\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maddfile(tarinfo, f)\n\u001b[1;32m   1981\u001b[0m \u001b[39melif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misdir():\n\u001b[1;32m   1982\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maddfile(tarinfo)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:2007\u001b[0m, in \u001b[0;36mTarFile.addfile\u001b[0;34m(self, tarinfo, fileobj)\u001b[0m\n\u001b[1;32m   2005\u001b[0m \u001b[39m# If there's data to follow, append it.\u001b[39;00m\n\u001b[1;32m   2006\u001b[0m \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2007\u001b[0m     copyfileobj(fileobj, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfileobj, tarinfo\u001b[39m.\u001b[39;49msize, bufsize\u001b[39m=\u001b[39;49mbufsize)\n\u001b[1;32m   2008\u001b[0m     blocks, remainder \u001b[39m=\u001b[39m \u001b[39mdivmod\u001b[39m(tarinfo\u001b[39m.\u001b[39msize, BLOCKSIZE)\n\u001b[1;32m   2009\u001b[0m     \u001b[39mif\u001b[39;00m remainder \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:250\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[0;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buf) \u001b[39m<\u001b[39m bufsize:\n\u001b[1;32m    249\u001b[0m         \u001b[39mraise\u001b[39;00m exception(\u001b[39m\"\u001b[39m\u001b[39munexpected end of data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m     dst\u001b[39m.\u001b[39;49mwrite(buf)\n\u001b[1;32m    252\u001b[0m \u001b[39mif\u001b[39;00m remainder \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    253\u001b[0m     buf \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mread(remainder)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.10/lib/python3.9/tarfile.py:435\u001b[0m, in \u001b[0;36m_Stream.write\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(s)\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomptype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtar\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 435\u001b[0m     s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcmp\u001b[39m.\u001b[39;49mcompress(s)\n\u001b[1;32m    436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__write(s)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "upload_dataset(\"processed\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download processed data from S3 (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch.config.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(directory: str) -> None:\n",
    "    \"\"\"\n",
    "    Get dataset from S3 bucket\n",
    "    \"\"\"\n",
    "    s3 = get_s3_resource()\n",
    "    object_name = (\n",
    "        f\"{settings.PROJECT_NAME}/{settings.DATA_DIR}/{directory}/{settings.ENV}.dataset.tar.gz\"\n",
    "    )\n",
    "    file_name = f\"{settings.DATA_DIR}/{directory}/dataset.tar.gz\"\n",
    "\n",
    "    try:\n",
    "        s3.Bucket(settings.MODELS_S3_BUCKET).download_file(\n",
    "            object_name,\n",
    "            file_name,\n",
    "        )\n",
    "        shutil.unpack_archive(file_name, directory)\n",
    "        os.remove(file_name)\n",
    "        logger.debug(\"Successfully downloaded dataset\")\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response[\"Error\"][\"Code\"] == \"404\":\n",
    "            logger.error(\"The object does not exist.\")\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-14 10:33.07 [debug    ] Successfully downloaded dataset\n"
     ]
    }
   ],
   "source": [
    "download_dataset(\"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e57bf46f634b5a832764381baf7500f30742567fea8abe7cdb26c193b5293ee6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
