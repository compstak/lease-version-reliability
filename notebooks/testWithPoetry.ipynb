{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jisooryu/Projects/lease-version-reliability\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import typing \n",
    "import structlog\n",
    "from lease_version_reliability.models.train import train_model\n",
    "from lease_version_reliability.models.inference import run_inference\n",
    "\n",
    "from lease_version_reliability.config.settings import settings \n",
    "from lease_version_reliability.data.database import (\n",
    "    CompstakServicesMySQL,\n",
    "    get_snowflake_connection,\n",
    ")\n",
    "from lease_version_reliability.data.database import cs_mysql_instance as mysql\n",
    "from lease_version_reliability.data.database_io import read_file\n",
    "\n",
    "logger = structlog.get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_inference(download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Submitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lease_version_reliability.config.attributes import attributes\n",
    "\n",
    "col = attributes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_reliability = [s + '_reliability' for s in col]\n",
    "col.insert(0,'submitter_person_id')\n",
    "col.insert(len(col), 'general_reliability')\n",
    "col_reliability.insert(0,'submitter_person_id')\n",
    "col_reliability.insert(len(col), 'general_reliability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = submitter_df[col_reliability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.set_axis(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "\n",
    "temp['date_created'] = pd.Timestamp.now()\n",
    "temp['date_created'] = temp['date_created'].dt.strftime('%Y-%m-%d %X')\n",
    "temp.columns = map(lambda x: str(x).upper(), temp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from snowflake.connector.pandas_tools import pd_writer\n",
    "\n",
    "conn = get_snowflake_connection()\n",
    "engine = create_engine(f\"snowflake://{settings.SNOWFLAKE_ACCOUNT}.{settings.SNOWFLAKE_REGION}.snowflakecomputing.com\", creator=lambda: conn)\n",
    "\n",
    "with engine.connect() as con:\n",
    "    temp.to_sql('submitter', engine, schema = 'LEASE_VERSION_RELIABILITY', index=False, if_exists='append', chunksize=10000, method=pd_writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = attributes.copy()\n",
    "col_reliability = [s + '_prob' for s in col]\n",
    "col.insert(0,'comp_data_id_version')\n",
    "col_reliability.insert(0,'comp_data_id_version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = version_df[col_reliability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = temp.set_axis(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['date_created'] = pd.Timestamp.now()\n",
    "temp['date_created'] = temp['date_created'].dt.strftime('%Y-%m-%d %X')\n",
    "temp.columns = map(lambda x: str(x).upper(), temp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = get_snowflake_connection()\n",
    "# engine = create_engine(f\"snowflake://{settings.SNOWFLAKE_ACCOUNT}.{settings.SNOWFLAKE_REGION}.snowflakecomputing.com\", creator=lambda: conn)\n",
    "\n",
    "# with engine.connect() as con:\n",
    "#     temp.to_sql('version', engine, schema = 'LEASE_VERSION_RELIABILITY', index=False, if_exists='append', chunksize=10000, method=pd_writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OOM Error - Read ALL_DATA in Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lease_version_reliability.data.database_io import get_logo_df, get_all_data, get_reliable_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_version_max_id(db: CompstakServicesMySQL) -> typing.Any:\n",
    "    \"\"\"\n",
    "    Retrun max id of comp_version table\n",
    "    \"\"\"\n",
    "\n",
    "    query = read_file(settings.SQL_QUERY, \"version_max_id.sql\")\n",
    "\n",
    "    return await db.fetch_val(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_all_versions(\n",
    "    db: CompstakServicesMySQL,\n",
    "    min: int,\n",
    "    max: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return version data from MySQL\n",
    "    \"\"\"\n",
    "    query = read_file(settings.SQL_QUERY, \"all_data.sql\").format(min=min, max=max)\n",
    "    data = [dict(item) for item in await db.fetch_all(query)]\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def temp_get_all_data(db:CompstakServicesMySQL) -> pd.DataFrame:\n",
    "    id = await get_version_max_id(mysql)\n",
    "    logger.info(\"Start processing lease data\")\n",
    "    all_df = pd.DataFrame()\n",
    "    for i in range(0, id, settings.BATCH_CONFIG.BATCH_SIZE):\n",
    "        logger.info(f\"Processing {i + settings.BATCH_CONFIG.BATCH_SIZE}/{id}\")\n",
    "        data = await get_all_versions(mysql, i, i + settings.BATCH_CONFIG.BATCH_SIZE)\n",
    "        all_df = pd.concat([all_df, data], ignore_index=True)\n",
    "    \n",
    "    all_df = await get_logo_df(all_df)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:databases:Connected to database mysql://admin:********@localhost:3308/compstak\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-01 10:30:33 [info     ] Start processing lease data\n",
      "2023-03-01 10:30:33 [info     ] Processing 500000/4017690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/_s14cy61779_h_jz170slph00000gq/T/ipykernel_97836/1252246593.py:10: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  data = [dict(item) for item in await db.fetch_all(query)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-01 10:31:57 [info     ] Processing 1000000/4017690\n",
      "2023-03-01 10:32:45 [info     ] Processing 1500000/4017690\n",
      "2023-03-01 10:33:44 [info     ] Processing 2000000/4017690\n",
      "2023-03-01 10:35:15 [info     ] Processing 2500000/4017690\n",
      "2023-03-01 10:36:42 [info     ] Processing 3000000/4017690\n",
      "2023-03-01 10:38:19 [info     ] Processing 3500000/4017690\n",
      "2023-03-01 10:40:23 [info     ] Processing 4000000/4017690\n",
      "2023-03-01 10:42:08 [info     ] Processing 4500000/4017690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:databases:Disconnected from database mysql://admin:********@localhost:3308/compstak\n"
     ]
    }
   ],
   "source": [
    "await mysql.connect()\n",
    "\n",
    "temp_all_df = await temp_get_all_data(mysql)\n",
    "\n",
    "await mysql.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2722225, 34)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:databases:Disconnected from database mysql://admin:********@localhost:3308/compstak\n"
     ]
    }
   ],
   "source": [
    "await mysql.connect()\n",
    "all_df = await get_all_data(mysql)\n",
    "await mysql.disconnect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliable Data - Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_reliable_data(\n",
    "    db: CompstakServicesMySQL,\n",
    "    min: int,\n",
    "    max: int,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return reliable data (more than 3 submitted versions) from MySQL\n",
    "    \"\"\"\n",
    "    query = read_file(settings.SQL_QUERY, \"reliable_data.sql\").format(min=min, max=max)\n",
    "    data = [dict(item) for item in await db.fetch_all(query)]\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def temp_get_reliable_data() -> pd.DataFrame:\n",
    "    id = await get_version_max_id(mysql)\n",
    "    logger.info(\"Start processing lease data\")\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(0, id, settings.BATCH_CONFIG.BATCH_SIZE):\n",
    "        logger.info(f\"Processing {i + settings.BATCH_CONFIG.BATCH_SIZE}/{id}\")\n",
    "        data = await get_reliable_data(mysql, i, i + settings.BATCH_CONFIG.BATCH_SIZE)\n",
    "        df = pd.concat([df, data], ignore_index=True)\n",
    "    \n",
    "    df = await get_logo_df(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q7/_s14cy61779_h_jz170slph00000gq/T/ipykernel_413/1643012004.py:6: RemovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to \"sqlalchemy<2.0\". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  data = [dict(item) for item in await db.fetch_all(query=query)]\n",
      "INFO:databases:Disconnected from database mysql://admin:********@localhost:3308/compstak\n"
     ]
    }
   ],
   "source": [
    "await mysql.connect()\n",
    "reliable_data = await get_reliable_data(mysql)\n",
    "await mysql.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-01 11:27:14 [info     ] Start processing lease data\n",
      "2023-03-01 11:27:14 [info     ] Processing 500000/4017690\n",
      "2023-03-01 11:28:26 [info     ] Processing 1000000/4017690\n",
      "2023-03-01 11:29:03 [info     ] Processing 1500000/4017690\n",
      "2023-03-01 11:29:45 [info     ] Processing 2000000/4017690\n",
      "2023-03-01 11:30:49 [info     ] Processing 2500000/4017690\n",
      "2023-03-01 11:31:46 [info     ] Processing 3000000/4017690\n",
      "2023-03-01 11:32:48 [info     ] Processing 3500000/4017690\n",
      "2023-03-01 11:33:39 [info     ] Processing 4000000/4017690\n",
      "2023-03-01 11:34:25 [info     ] Processing 4500000/4017690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:databases:Disconnected from database mysql://admin:********@localhost:3308/compstak\n"
     ]
    }
   ],
   "source": [
    "await mysql.connect()\n",
    "temp_reliable_data = await temp_get_reliable_data()\n",
    "await mysql.disconnect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label attributes to vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lease-version-reliability-temp-py3.9.10",
   "language": "python",
   "name": "lease-version-reliability-temp-py3.9.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "562e7dfc617b32736c71df661251deda0bf08d043947763a310a583b3747228d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
